{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anagram game code. Anagrams are different words which can be made from same set of letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's load the dictionary. We will use this dictionary as a reference to find out whether a combination of letters is a valid word or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Open the TXT file and append in a List called words'\n",
    "words = []\n",
    "for line in open('C:/Users/Public.DESKTOP-6RBQT7L/Desktop/Programming - Maths/LinkedIn Learning - Data analysis Python course/chapter3/words.txt', 'r'):\n",
    "    words.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A\\n',\n",
       " 'a\\n',\n",
       " 'aa\\n',\n",
       " 'aal\\n',\n",
       " 'aalii\\n',\n",
       " 'aam\\n',\n",
       " 'Aani\\n',\n",
       " 'aardvark\\n',\n",
       " 'aardwolf\\n',\n",
       " 'Aaron\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Let\\'s see a sample of the \"words\" list'\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word has a '\\n' new line character; also words are a mix of upper-case lower-case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aaron'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Aaron\\n'.strip() # strip() removes any special characters from the beginning and ending. let's apply this to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaron'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Aaron\\n'.strip().lower() # Let's convert everything to lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for line in open('C:/Users/Public.DESKTOP-6RBQT7L/Desktop/Programming - Maths/LinkedIn Learning - Data analysis Python course/chapter3/words.txt', 'r'):\n",
    "    words.append(line.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10] # Now it is all sorted. But there are duplicates like word \"a\" for example. Let's use a set instead of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "for line in open('C:/Users/Public.DESKTOP-6RBQT7L/Desktop/Programming - Maths/LinkedIn Learning - Data analysis Python course/chapter3/words.txt', 'r'):\n",
    "    words.add(line.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use set comprehension to use the above command to make it more Pythonic\n",
    "\n",
    "words=set()\n",
    "words = {line.strip().lower() for line in open('C:/Users/Public.DESKTOP-6RBQT7L/Desktop/Programming - Maths/LinkedIn Learning - Data analysis Python course/chapter3/words.txt', 'r')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chamaesiphonales',\n",
       " 'cholecystectomy',\n",
       " 'deuterotokous',\n",
       " 'eggberry',\n",
       " 'pentaphylacaceous'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(random.sample(words, 5)) #slicing in the 'words' set to return 5 random entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dictionary from words.txt file is over now. Let's move on to the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'd', 'f', 'l', 'o', 'r', 'w']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does sorted function do\n",
    "sorted('aardwolf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If sorted(word-1) == sorted(word-2), then word-1 and word-2 are anagrams\n",
    "sorted('lives')==sorted('elvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eilsv'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(sorted('elvis')) #first sort and then join together. This is called Signature of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate Signature of a word:\n",
    "def signature(word):\n",
    "    return ''.join(sorted(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare signature of user's word with the signature of each word in the dictionary\n",
    "# If signture is same, that means they are anagrams\n",
    "# This is called brute-force method as we check anagram of each word in dictionary and then compare\n",
    "\n",
    "# Define a function to do this comparison and return the word if signature matches\n",
    "\n",
    "def isanagram(myword):\n",
    "    for word in words:\n",
    "        if signature(myword) == signature(word):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary\n",
      "indicatory\n"
     ]
    }
   ],
   "source": [
    "isanagram('dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary\n",
      "indicatory\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "# Find out how long does it take to execute\n",
    "\n",
    "%time isanagram('dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it in a smarter way rather than brute-force way\n",
    "\n",
    "# Let's create a new dictionary, where 'key' will be the signature, and 'value' will be different words with same signature\n",
    "\n",
    "words_by_sig = collections.defaultdict(set)\n",
    "\n",
    "for word in words:\n",
    "    words_by_sig[signature(word)].add(word)\n",
    "    \n",
    "    # signature(word) is the 'key'\n",
    "    # add(word) is the 'value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acilnoortu': {'inoculator'},\n",
       " 'abeeefiilnnrssuv': {'unverifiableness'},\n",
       " 'adeemnr': {'amender', 'meander', 'reamend', 'reedman'},\n",
       " 'bdgllou': {'bulldog'},\n",
       " 'aefflmoorw': {'foamflower'},\n",
       " 'nptu': {'punt'},\n",
       " 'eeiiorttv': {'orvietite'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(itertools.islice(words_by_sig.items(), 7))\n",
    "\n",
    "# slicing the dictionary to see a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now there will also be single letter words like 'a'. These can be removed by following dictionary-comprehension code\n",
    "\n",
    "anagrams_by_sig = {sig:wordset for sig, wordset in words_by_sig.items() if len(wordset) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adeemnr': {'amender', 'meander', 'reamend', 'reedman'},\n",
       " 'ahiprst': {'harpist', 'traship'},\n",
       " 'prtu': {'prut', 'turp'},\n",
       " 'acdehiprst': {'dispatcher', 'redispatch'},\n",
       " 'enptuw': {'unwept', 'upwent'},\n",
       " 'eflrru': {'furler', 'refurl'},\n",
       " 'aacilnt': {'actinal', 'alantic', 'alicant', 'antical'}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(itertools.islice(anagrams_by_sig.items(), 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now let's define a new function which will take a word as input and then based on the signature of that word, will return \n",
    "all the 'values' for the 'key'=signature_of_the_word\n",
    "'''\n",
    "\n",
    "def find_anagrams_fast(myword):\n",
    "    return anagrams_by_sig.get( signature(myword), 'No anagrams exist!' )\n",
    "\n",
    "# What this is doing is: first find the Signature of the word, then pass that into the anagrams_by_sig dictionary as 'key'\n",
    "# And for that 'key' return all the 'values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dictionary', 'indicatory'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_anagrams_fast('dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dictionary', 'indicatory'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time find_anagrams_fast('dictionary') #compare this to the earlier time taken! That's the power of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No anagrams exist!'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_anagrams_fast('nikhil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's play a little bit with our Anagrams Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out which are the longest anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acddeehiimmnoopprrruuy',\n",
       " 'ccddeehlmnooooossttuyy',\n",
       " 'aaabegghilllnoooprssy',\n",
       " 'aaccddeeemnnoooprttuy',\n",
       " 'aaaaccghiillmnooooptt',\n",
       " 'acghhhhilmooooopprrtt',\n",
       " 'aaccghiiilmnoooopsty',\n",
       " 'aaabeggillllnooorssy',\n",
       " 'acceeeeeghillmnnnoop',\n",
       " 'aacccdeehiiinopprrr']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( anagrams_by_sig.keys(), key=len, reverse=True )[:10] #Just first 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But the above is only giving us keys. Let's see what are the actual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hydropneumopericardium', 'pneumohydropericardium'},\n",
       " {'cholecystoduodenostomy', 'duodenocholecystostomy'},\n",
       " {'glossolabiopharyngeal', 'labioglossopharyngeal'},\n",
       " {'duodenopancreatectomy', 'pancreatoduodenectomy'},\n",
       " {'anatomicopathological', 'pathologicoanatomical'},\n",
       " {'chromophotolithograph', 'photochromolithograph'},\n",
       " {'anatomicophysiologic', 'physiologicoanatomic'},\n",
       " {'glossolabiolaryngeal', 'labioglossolaryngeal'},\n",
       " {'encephalomeningocele', 'meningoencephalocele'},\n",
       " {'pericardiacophrenic', 'phrenicopericardiac'}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[anagrams_by_sig.get(new_list) for new_list in sorted(anagrams_by_sig.keys(), key=len, reverse=True)][0:10] #first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's find which 'key' has maximum number of 'values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'angor',\n",
       "  'argon',\n",
       "  'goran',\n",
       "  'grano',\n",
       "  'groan',\n",
       "  'nagor',\n",
       "  'orang',\n",
       "  'organ',\n",
       "  'rogan',\n",
       "  'ronga'},\n",
       " {'elaps',\n",
       "  'lapse',\n",
       "  'lepas',\n",
       "  'pales',\n",
       "  'salep',\n",
       "  'saple',\n",
       "  'sepal',\n",
       "  'slape',\n",
       "  'spale',\n",
       "  'speal'},\n",
       " {'armet',\n",
       "  'mater',\n",
       "  'merat',\n",
       "  'metra',\n",
       "  'ramet',\n",
       "  'tamer',\n",
       "  'terma',\n",
       "  'trame',\n",
       "  'trema'},\n",
       " {'asteer',\n",
       "  'easter',\n",
       "  'eastre',\n",
       "  'reseat',\n",
       "  'saeter',\n",
       "  'seater',\n",
       "  'staree',\n",
       "  'teaser',\n",
       "  'teresa'},\n",
       " {'caret',\n",
       "  'carte',\n",
       "  'cater',\n",
       "  'crate',\n",
       "  'creat',\n",
       "  'creta',\n",
       "  'react',\n",
       "  'recta',\n",
       "  'trace'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(anagrams_by_sig.values(), key=len, reverse=True )[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add length (i.e. number of 'values') to be printed alongth for each set of 'values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 10\n",
      "{'ronga', 'groan', 'goran', 'rogan', 'argon', 'orang', 'angor', 'grano', 'organ', 'nagor'}\n",
      "*****************************\n",
      "Length: 10\n",
      "{'saple', 'slape', 'spale', 'lapse', 'elaps', 'speal', 'sepal', 'pales', 'lepas', 'salep'}\n",
      "*****************************\n",
      "Length: 9\n",
      "{'trame', 'ramet', 'trema', 'armet', 'tamer', 'merat', 'mater', 'terma', 'metra'}\n",
      "*****************************\n",
      "Length: 9\n",
      "{'teaser', 'eastre', 'seater', 'reseat', 'easter', 'asteer', 'saeter', 'teresa', 'staree'}\n",
      "*****************************\n",
      "Length: 9\n",
      "{'crate', 'recta', 'carte', 'caret', 'creta', 'react', 'creat', 'trace', 'cater'}\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(anagrams_by_sig.values(), key=len, reverse=True )[0:5]:\n",
    "    print('Length:',len(x))\n",
    "    print(x)\n",
    "    print(\"*****************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extend the above logic to find palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'radar' == 'radar'[::-1] #Checking palindrome through slicing, which is used to reverse a given string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the set of individual letters in the palindrome pair is exactly the same.\n",
    "That means, if we refer to our \"anagrams_by_sig\" dictionary, they will be having the same 'key' (i.e. signature).\n",
    "This means, we can loop through each signature in our \"anagrams_by_sig\" dictionary, and within each set of 'values' we will compare if any of them are palindromes of each other.\n",
    "This saves us time because we won't be comparing 2 words, say 'radar' and 'elephant' at all because their signatures are different.\n",
    "Hence, comparing by 'signature' of the word helps us to improve our performance drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "palindromes = []\n",
    "\n",
    "for wordset in anagrams_by_sig.values():\n",
    "    for word1 in wordset:\n",
    "        for word2 in wordset:\n",
    "            if word1 >= word2 and word1 == word2[::-1]:\n",
    "                palindromes.append((word1,word2))\n",
    "\n",
    "# So in this we are taking each set of 'words' in 'wordset' and comparing with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(palindromes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turp', 'prut'),\n",
       " ('na', 'an'),\n",
       " ('lina', 'anil'),\n",
       " ('sina', 'anis'),\n",
       " ('sain', 'nias'),\n",
       " ('yard', 'dray'),\n",
       " ('sita', 'atis'),\n",
       " ('wo', 'ow'),\n",
       " ('oda', 'ado'),\n",
       " ('tracer', 'recart')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palindromes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Itertools.combinations() to give us set of words for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baroda', 'sharma'), ('Baroda', 'nikhil'), ('sharma', 'nikhil')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations({'nikhil', 'sharma', 'Baroda'}, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "palindromes = []\n",
    "\n",
    "for wordset in anagrams_by_sig.values():\n",
    "    for word1, word2 in itertools.combinations(wordset, 2):\n",
    "        if word1[::-1] == word2:\n",
    "            palindromes.append((word1, word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turp', 'prut'),\n",
       " ('na', 'an'),\n",
       " ('anil', 'lina'),\n",
       " ('sina', 'anis'),\n",
       " ('nias', 'sain'),\n",
       " ('dray', 'yard'),\n",
       " ('atis', 'sita'),\n",
       " ('ow', 'wo'),\n",
       " ('oda', 'ado'),\n",
       " ('recart', 'tracer')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palindromes[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
